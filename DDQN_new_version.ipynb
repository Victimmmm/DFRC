{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UEqfahOuUb_s"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.optimizers import Adam\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFL3wbXPTUCd"
   },
   "source": [
    "#DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mSaTRvn1TWcV"
   },
   "outputs": [],
   "source": [
    "class DoubleDeepQNetwork():\n",
    "    def __init__(self, states, actions, alpha, gamma, epsilon,epsilon_min, epsilon_decay):\n",
    "        self.nS = states\n",
    "        self.nA = actions\n",
    "        self.memory = deque([], maxlen=2000)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        #Explore/Exploit\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = self.build_model()\n",
    "        self.model_target = self.build_model() #Second (target) neural network\n",
    "        self.update_target_from_model() #Update weights\n",
    "        self.loss = []\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = keras.Sequential() #linear stack of layers https://keras.io/models/sequential/\n",
    "        model.add(keras.layers.Dense(32, input_dim=self.nS, activation='relu')) #[Input] -> Layer 1\n",
    "        #   Dense: Densely connected layer https://keras.io/layers/core/\n",
    "        #   24: Number of neurons\n",
    "        #   input_dim: Number of input variables\n",
    "        #   activation: Rectified Linear Unit (relu) ranges >= 0\n",
    "        model.add(keras.layers.Dense(1024, activation='relu', kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.L1(0.0), activity_regularizer=tf.keras.regularizers.L2(0.1)))\n",
    "        model.add(keras.layers.Dense(1024, activation='relu', kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.L1(0.0), activity_regularizer=tf.keras.regularizers.L2(0.1)))\n",
    "        model.add(keras.layers.Dense(1024, activation='relu', kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.L1(0.0), activity_regularizer=tf.keras.regularizers.L2(0.1)))\n",
    "        model.add(keras.layers.Dense(self.nA, activation='linear')) #Layer 3 -> [output]\n",
    "        #   Size has to match the output (different actions)\n",
    "        #   Linear activation on the last layer\n",
    "        model.compile(loss='mean_squared_error', #Loss function: Mean Squared Error\n",
    "                      optimizer=keras.optimizers.Adam(lr=self.alpha)) #Optimaizer: Adam (Feel free to check other options)\n",
    "        return model\n",
    "\n",
    "    def update_target_from_model(self):\n",
    "        #Update the target model from the base model\n",
    "        self.model_target.set_weights( self.model.get_weights() )\n",
    "\n",
    "    def action(self, env, state):\n",
    "        A = np.random.random()\n",
    "        if A <= self.epsilon:\n",
    "          action = env.sam_action() #Explore\n",
    "          return action\n",
    "        else:        \n",
    "          action_vals = self.model.predict(state) #Exploit: Use the NN to predict the correct action from this state\n",
    "          act_idx = np.argmax(action_vals[0])\n",
    "          action = env.index2action(act_idx)\n",
    "          return action\n",
    "        \n",
    "\n",
    "    def test_action(self, env,state): #Exploit\n",
    "        action_vals = self.model.predict(state)\n",
    "        act_idx = np.argmax(action_vals[0])\n",
    "        action = env.index2action(act_idx)\n",
    "        return action \n",
    "\n",
    "    def store(self, state, action, reward, nstate, done):\n",
    "        #Store the experience in memory\n",
    "        self.memory.append( (state, action, reward, nstate, done) )\n",
    "\n",
    "    def experience_replay(self, env, batch_size):\n",
    "        #Execute the experience replay\n",
    "        minibatch = random.sample( self.memory, batch_size) #Randomly sample from memory\n",
    "\n",
    "        #Convert to numpy for speed by vectorization\n",
    "        x = []\n",
    "        y = []\n",
    "        np_array = np.array(minibatch)\n",
    "        st = np.zeros((0,self.nS)) #States\n",
    "        nst = np.zeros( (0,self.nS) )#Next States\n",
    "        for i in range(len(np_array)): #Creating the state and next state np arrays\n",
    "            st = np.append( st, np_array[i,0], axis=0)\n",
    "            nst = np.append( nst, np_array[i,3], axis=0) # Because the store includes state, action, reward, nstate, and done\n",
    "        st_predict = self.model.predict(st) #Here is the speedup! I can predict on the ENTIRE batch\n",
    "        #print(f\"st_predict:{st_predict}\")\n",
    "        nst_predict = self.model.predict(nst)\n",
    "        nst_predict_target = self.model_target.predict(nst) #Predict from the TARGET\n",
    "        index = 0\n",
    "        for state, action, reward, nstate, done in minibatch:\n",
    "            x.append(state)\n",
    "            #Predict from state\n",
    "            nst_action_predict_target = nst_predict_target[index]\n",
    "            nst_action_predict_model = nst_predict[index]\n",
    "            if done == True: #Terminal: Just assign reward much like {* (not done) - QB[state][action]}\n",
    "                target = reward\n",
    "            else:   #Non terminal\n",
    "                target = reward + self.gamma * nst_action_predict_target[np.argmax(nst_action_predict_model)] #Using Q to get T is Double DQN\n",
    "\n",
    "            #print(f\"target:{target}\") \n",
    "            target_f = st_predict[index]\n",
    "            #print(f\"target_f:{target_f}\")  \n",
    "            #print(f\"size target_f:{target_f.shape}\") \n",
    "            idx = env.action2index(action)\n",
    "            #print(f\"idx:{int(idx)}\") \n",
    "            #print(f\"target_f[2]:{target_f[2]}\") \n",
    "            target_f[int(idx)] = target\n",
    "            y.append(target_f)\n",
    "            index += 1\n",
    "        #Reshape for Keras Fit\n",
    "        x_reshape = np.array(x).reshape(batch_size,self.nS)\n",
    "        y_reshape = np.array(y)\n",
    "        epoch_count = 1\n",
    "        hist = self.model.fit(x_reshape, y_reshape, epochs=epoch_count, verbose=0)\n",
    "        #Graph Losses\n",
    "        for i in range(epoch_count):\n",
    "            self.loss.append( hist.history['loss'][i] )\n",
    "        #Decay Epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return self.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iABSlTzMTeaB"
   },
   "source": [
    "#Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "error",
     "timestamp": 1669453429718,
     "user": {
      "displayName": "Hoai Linh Nguyen Thi",
      "userId": "09006753140999843619"
     },
     "user_tz": -420
    },
    "id": "65gjhglATYyi",
    "outputId": "6e6c8055-f6e0-4c08-9bce-b45ffcd24cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.0\n",
      "[3, 0.0, 1.0, 1.0, 0.0, 0.0, 2] [3, 0, 1, 1, 0, 0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "class Helper:\n",
    "    def __init__(self, rc, max_f, max_c):\n",
    "        \"\"\"\n",
    "        Initial Method for Continuous Environment\n",
    "        params - rc: float - Radius Cycle\n",
    "        params - max_f: float - Maximum CPUs\n",
    "        params - max_c: float - Maximum Costs\n",
    "        \"\"\"\n",
    "        if rc < 0 or max_f < 0 or max_c < 0:\n",
    "            raise Exception(\n",
    "                    \"Initial Values for Helper must be Positive!\"\n",
    "                )\n",
    "        self.rc = rc\n",
    "        self.max_f = max_f\n",
    "        self.max_c = max_c\n",
    "\n",
    "        self.f = None\n",
    "        self.c = None\n",
    "\n",
    "    def become_stranger(self):\n",
    "        \"\"\"This node become to a Stranger Node\"\"\"\n",
    "        f_frac = np.random.uniform(low=1e-6, high=1e-5)\n",
    "        c_frac = np.random.uniform(low=0.08, high=0.01)\n",
    "        self.f = self.f * f_frac\n",
    "        self.c = self.c * c_frac\n",
    "\n",
    "        if np.random.rand() < 0.9:\n",
    "            self.c = self.c  * f_frac * np.random.uniform(low=10.0, high=20.0)\n",
    "        else:\n",
    "            self.c = self.c * f_frac\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Create a New Instance\n",
    "        \"\"\"\n",
    "        self.f = np.random.normal(loc=self.max_f * 0.5, scale=self.max_f * 1e-4)\n",
    "        self.c = np.random.normal(loc=self.max_c * 0.5, scale=self.max_c * 1e-4)\n",
    "\n",
    "        # if np.random.rand() < 0.1:\n",
    "        #     self.become_stranger()\n",
    "\n",
    "        if self.f < 0:\n",
    "            self.f = self.max_f * 0.5\n",
    "        if self.c < 0:\n",
    "            self.c = self.max_c * 0.5\n",
    "\n",
    "    def transit(self):\n",
    "        \"\"\"\n",
    "        Move to a Next State\n",
    "        \"\"\"\n",
    "        self.f = np.random.normal(loc=self.f, scale=self.max_f * 1e-4)\n",
    "        self.c = np.random.normal(loc=self.c, scale=self.max_c * 1e-4)\n",
    "\n",
    "        if self.f < 0:\n",
    "            self.f = self.max_f * 0.5\n",
    "\n",
    "        if self.c < 0:\n",
    "            self.c = self.max_c * 0.5\n",
    "\n",
    "        # if np.random.rand() < 0.1:\n",
    "        #     self.become_stranger()\n",
    "\n",
    "    def cal_com_latency(self, num_bytes):\n",
    "        \"\"\"\n",
    "        Calculate The Latency for Computing \"num_bytes\" data \n",
    "        params: num_bytes - Integer - Computation Demand\n",
    "        \"\"\"\n",
    "        num_bytes = float(num_bytes)\n",
    "        latency = num_bytes / self.f\n",
    "        return latency\n",
    "\n",
    "    def cal_offload_latency(self, num_bytes, mu, m, d_n):\n",
    "        \"\"\"\n",
    "        Calculate The Latency for Offloading \"num_bytes\" data\n",
    "        params: num_bytes - Integer - Offloading Demand\n",
    "        \"\"\"\n",
    "        num_bytes = float(num_bytes)\n",
    "        # Transformation Parameters\n",
    "        CO = 3*1e8\n",
    "        Fc = 1e4\n",
    "        BW = 10e7\n",
    "        G_RA = 1.8\n",
    "        P_max = 250*10**(-3)\n",
    "        Loss_free = (4*np.pi* Fc * d_n/CO)**2\n",
    "        sigma_2 = 4*10**(-21)\n",
    "\n",
    "        pr = (mu*P_max*(G_RA)**2)/Loss_free\n",
    "        SNR = m*pr/(BW*sigma_2)\n",
    "        rn = (BW/m) * np.log2(1.0 + SNR) \n",
    "        latency = num_bytes / rn\n",
    "        return latency\n",
    "\n",
    "    def cal_incentive_cost(self, num_bytes):\n",
    "        \"\"\"\n",
    "        Calculate the Incentive Cost for Processing \"num_bytes\" data\n",
    "        params: - num_bytes : Integer\n",
    "        \"\"\"\n",
    "        cost = self.c * self.cal_com_latency(num_bytes)\n",
    "        return cost\n",
    "\n",
    "    def show_cur_state(self):\n",
    "        print(\"d: {:.3f}, f: {:.3f}, c: {:.10f}\".format(self.d, self.f, self.c))\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Get the Current State of This Helper\n",
    "        \"\"\"\n",
    "        state = [self.f/self.max_f, self.c/self.max_c]\n",
    "\n",
    "        return state\n",
    "\n",
    "class TaskOffloadEnv:\n",
    "    def __init__(self, n_helpers, rc, max_f, max_c, max_l, alpha1, alpha2, alpha3, alpha4, v_min, v_max,  seed):\n",
    "        \"\"\"\n",
    "        Initial Method for Task Offload Environments\n",
    "        \"\"\"\n",
    "        self.n_helpers = n_helpers\n",
    "\n",
    "        self.rc = rc\n",
    "        self.max_f = max_f\n",
    "        self.max_c = max_c\n",
    "        self.max_l = max_l\n",
    "\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.alpha3 = alpha3\n",
    "        self.alpha4 = alpha4\n",
    "        self.helpers = {}\n",
    "        self.step_counter = 0\n",
    "\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "\n",
    "        self.curr_n_helpers = self.n_helpers\n",
    "\n",
    "        # environment's configuration\n",
    "        self.act_dims = [self.n_helpers] + [2 for _ in range(self.n_helpers)] + [2] \n",
    "        self.num_actions = self.n_helpers * (2 ** self.n_helpers) * 2\n",
    "        self.env_dims = 2 + self.n_helpers * 6\n",
    "\n",
    "        # Client initialization\n",
    "        self.x_0 = 0\n",
    "        self.y_0 = 0\n",
    "        self.v_x = 0\n",
    "        self.v_y = 0\n",
    "\n",
    "        self.userList_x = []\n",
    "        self.userList_y = []\n",
    "        self.userList_location = []\n",
    "        \n",
    "        self.userList_velocity_x = []\n",
    "        self.userList_velocity_y = []\n",
    "        self.userList_velocity = []\n",
    "\n",
    "        self.d_n = 0\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def _clientInit(self, ):\n",
    "      for user_no in range(self.n_helpers):\n",
    "        user_Radius = random.uniform(self.rc/2, self.rc)\n",
    "        line = [1,3]\n",
    "        line = random.choice(line)\n",
    "        if line == 1:\n",
    "          user_Angle  = math.asin(self.rc/2/user_Radius)\n",
    "        # elif line == 2:\n",
    "        #   user_Angle  = math.asin(0/user_Radius)\n",
    "        else:\n",
    "          user_Angle  = math.asin(-self.rc/2/user_Radius)\n",
    "\n",
    "        user_x1 = self.x_0 + user_Radius * math.cos(user_Angle)\n",
    "        user_x2 = self.x_0 - user_Radius * math.cos(user_Angle)\n",
    "        user_x = random.choice([user_x1, user_x2])\n",
    "        user_y = self.y_0 + user_Radius * math.sin(user_Angle)\n",
    "\n",
    "        # velocity\n",
    "        user_vy= 0\n",
    "        user_vx = random.uniform(self.v_min , self.v_max)\n",
    "        self.userList_x.append(user_x)\n",
    "        self.userList_y.append(user_y)\n",
    "        self.userList_location.append([user_x, user_y])\n",
    "        self.userList_velocity.append([user_vx, user_vy])\n",
    "\n",
    "      # # Client Plot\n",
    "      # fig, ax = plt.subplots()                                                \n",
    "      # circle1 = plt.Circle((self.x_0, self.y_0), self.rc, color='b', fill=False) \n",
    "      # circle2 = plt.Circle((self.x_0, self.y_0), 1, color='r', fill=True)       \n",
    "      # ax.add_patch(circle1)\n",
    "      # ax.add_patch(circle2)\n",
    "      # print(f\"List of user location is: {self.userList_location}\")\n",
    "      # print(f\"List of user velocity is: {self.userList_velocity}\")\n",
    "      # plt.scatter(self.userList_x, self.userList_y)\n",
    "      # plt.show()\n",
    "    \n",
    "    def distance(self):\n",
    "      userList_distance = []            \n",
    "      # init client location:               \n",
    "      client_location = (self.x_0, self.y_0)\n",
    "      for user_no in range(self.n_helpers):\n",
    "        #print(f\"user_no {user_no}\")\n",
    "        user_distance = np.linalg.norm(np.array(self.userList_location[user_no]) - np.array(client_location))\n",
    "        userList_distance.append(user_distance)\n",
    "      #print(f\"List of user distance is: {userList_distance}\")\n",
    "      return userList_distance\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Get Environment State\n",
    "        \"\"\"\n",
    "        \n",
    "        client_state = [self.l*1.0/self.max_l]\n",
    "        helper_state = []\n",
    "        userList_distance = self.distance()\n",
    "        num_helpers = 0\n",
    "        for key in sorted(list(self.helpers.keys())):                    \n",
    "          if userList_distance[key] > self.rc:\n",
    "            state_f_c = [0,0]\n",
    "          else:\n",
    "            helper = self.helpers[key]\n",
    "            state_f_c = helper.get_state()\n",
    "            num_helpers = num_helpers + 1\n",
    "          location = self.userList_location[key]\n",
    "          x = location[0]/self.rc\n",
    "          y = location[1]/self.rc\n",
    "          position = [x,y]\n",
    "          velocity = self.userList_velocity[key]\n",
    "          v_x = velocity[0]/self.v_max\n",
    "          v_y = velocity[1]/self.v_max\n",
    "          v= [v_x, v_y]\n",
    "          state = position + v + state_f_c\n",
    "          helper_state += state\n",
    "          \n",
    "        env_state = [num_helpers] + client_state + helper_state\n",
    "        #print(f\"env_state : {env_state}\")\n",
    "        return env_state\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Create a New Instance\n",
    "        \"\"\"\n",
    "        self._clientInit()\n",
    "        self.l = np.random.normal(loc=self.max_l * 0.5, scale=self.max_l * 1e-6)\n",
    "        if self.l < 0:\n",
    "            self.l = self.max_l * 0.5\n",
    "        self.step_counter = 0\n",
    "        for idx in range(self.n_helpers):\n",
    "            self.helpers[idx] = Helper(self.rc, self.max_f, self.max_c)\n",
    "            self.helpers[idx].reset()            \n",
    "        self.client_f = self.max_f * np.random.normal(loc=0.0001, scale= 1e-6)\n",
    "\n",
    "        state = self.get_state()\n",
    "        #print(f\"List of user state is: {state}\")\n",
    "        return state\n",
    "\n",
    "    def Markov_chain(self,num_n_vehicles):\n",
    "\n",
    "      n_vehicle_state = {0 : \"N1\",1 : \"N2\",2 : \"N3\", 3 : \"N4\", 4 : \"N5\"}\n",
    "      State_1 = [0.4, 0.5, 0.05, 0.05, 0]\n",
    "      State_2 = [0.3, 0.2, 0.3, 0.1, 0.1]\n",
    "      State_3 = [0, 0.3, 0.3, 0.4, 0]\n",
    "      State_4 = [0.05, 0.05, 0.3, 0.3, 0.3]\n",
    "      State_5 = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "      transitionMatrix = np.array([State_1, State_2, State_3, State_4, State_5])\n",
    "      activityList = []\n",
    "      start_n_vehicles = num_n_vehicles - 1 \n",
    "      next_n_vehicles = np.random.choice([0,1,2,3,4], p = transitionMatrix[start_n_vehicles])\n",
    "      return next_n_vehicles + 1\n",
    "\n",
    "    def transmit(self, curr_n_vehicles):\n",
    "      # x = x + v_x*t, y = y + v_y*t\n",
    "      y_vecto = []\n",
    "      over_n_vehicles = 0\n",
    "      index = []\n",
    "      for user_no in range(self.n_helpers):\n",
    "        self.userList_location[user_no][0] = self.userList_location[user_no][0] + self.userList_velocity[user_no][0]\n",
    "        self.userList_location[user_no][1] = self.userList_location[user_no][1] + self.userList_velocity[user_no][1]\n",
    "\n",
    "      userList_distance = self.distance()\n",
    "      for user_no in range(self.n_helpers):\n",
    "        if userList_distance[user_no] > self.rc:\n",
    "          over_n_vehicles += 1\n",
    "          index.append(user_no)\n",
    "      remain_n_vehicles = curr_n_vehicles - over_n_vehicles\n",
    "\n",
    "      next_n_vehicles = self.Markov_chain(remain_n_vehicles)\n",
    "\n",
    "      if next_n_vehicles > remain_n_vehicles:\n",
    "        add_num = next_n_vehicles - remain_n_vehicles\n",
    "        #print(f\"add_num: {add_num}\")\n",
    "        for i in range(add_num):\n",
    "            idx = index[i]\n",
    "            self.userList_location[idx], self.userList_velocity[idx] = self.out_of_range(add_num) \n",
    "        curr_n_vehicles = next_n_vehicles\n",
    "\n",
    "      else:\n",
    "        curr_n_vehicles = remain_n_vehicles     \n",
    "      #print(f\"curr_n_vehicles is: {curr_n_vehicles}\")\n",
    "      for key in self.helpers.keys():\n",
    "        self.helpers[key].transit()\n",
    "\n",
    "      # fig, ax = plt.subplots()                                                \n",
    "      # circle1 = plt.Circle((self.x_0, self.y_0), self.rc, color='b', fill=False) \n",
    "      # circle2 = plt.Circle((self.x_0, self.y_0), 1, color='r', fill=True)       \n",
    "      # ax.add_patch(circle1)\n",
    "      # ax.add_patch(circle2)\n",
    "      # userList_x,userList_y = [],[]\n",
    "      # for user_no in range(self.n_helpers):\n",
    "      #   x = self.userList_location[user_no][0]\n",
    "      #   y= self.userList_location[user_no][1]\n",
    "      #   userList_x.append(x)\n",
    "      #   userList_y.append(y)\n",
    "      # plt.scatter(userList_x, userList_y)\n",
    "      # plt.show()\n",
    "    \n",
    "    def out_of_range(self, num):\n",
    "      # When vehicles go through the circle\n",
    "        user_Radius = random.uniform(self.rc/2, self.rc)\n",
    "        line = [1,3]\n",
    "        line = random.choice(line)\n",
    "        if line == 1:\n",
    "          user_Angle  = math.asin(self.rc/2/user_Radius)\n",
    "        # elif line == 2:\n",
    "        #   user_Angle  = math.asin(0/user_Radius)\n",
    "        else:\n",
    "          user_Angle  = math.asin(-self.rc/2/user_Radius)\n",
    "\n",
    "        user_x = self.x_0 - user_Radius * math.cos(user_Angle)\n",
    "        user_y = self.y_0 + user_Radius * math.sin(user_Angle)\n",
    "\n",
    "        # velocity\n",
    "        user_vy= 0\n",
    "        user_vx = random.uniform(self.v_min , self.v_max)\n",
    "        location = [user_x, user_y]\n",
    "        velocity = [user_vx, user_vy]\n",
    "        return location, velocity\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Perform an action\n",
    "        action's format [k, a1, ..., aN, B_c]\n",
    "\n",
    "        \"\"\"\n",
    "        done = False\n",
    "        c0 = 3*10**8\n",
    "        P_max = 250*10**(-3)\n",
    "        G_RA = 1.8\n",
    "        sigma_c = 100\n",
    "        P_ra_min = 10**(-13)\n",
    "        Lambda = 0.1\n",
    "        f_rad = 76*10**9\n",
    "\n",
    "        k = action[0]\n",
    "        if action[-1] == 1:\n",
    "          Power = 0.7\n",
    "        else:\n",
    "          Power = 0.9\n",
    "        mu = Power\n",
    "        a_vec = action[-self.n_helpers-1:-1]\n",
    "        m = sum(a_vec)\n",
    "        standard_time = self.l / self.client_f      \n",
    "        com_fee, total_latency, required_connect = [], [], []\n",
    "        num_bytes = self.l / k\n",
    "        userList_distance = self.distance()\n",
    "        for idx in sorted(list(self.helpers.keys())):\n",
    "            if a_vec[idx] == 0:\n",
    "                total_latency.append(np.Inf)\n",
    "                com_fee.append(0.0)\n",
    "                required_connect.append(0.0)\n",
    "            else:\n",
    "                helper = self.helpers[idx]\n",
    "                d_n = userList_distance[idx]\n",
    "                offload_latency = helper.cal_offload_latency(num_bytes, mu, m, d_n)\n",
    "                com_latency = helper.cal_com_latency(num_bytes)\n",
    "                fee = helper.cal_incentive_cost(num_bytes)\n",
    "                com_fee.append(fee)\n",
    "                total_n = offload_latency + com_latency\n",
    "                total_latency.append(total_n)\n",
    "                duration = self.constrain(self.rc, self.userList_velocity[idx][0], 0 , d_n, 0)\n",
    "                if total_n <= duration:\n",
    "                  rw_link =  Lambda\n",
    "                else:\n",
    "                  rw_link = 0\n",
    "                required_connect.append(rw_link)\n",
    "\n",
    "        total_latency = sorted(total_latency)\n",
    "        required_latency = max(total_latency[:k])\n",
    "        required_fee = np.sum(com_fee)\n",
    "        connect_rw = np.sum(required_connect)\n",
    "        lamda_rad = c0/f_rad\n",
    "        res_max = (P_max*(G_RA)**2*lamda_rad**2*sigma_c/(4*(np.pi)**2*P_ra_min))**(1/4)\n",
    "        res = ((1-mu)*P_max*(G_RA)**2*lamda_rad**2*sigma_c/(4*(np.pi)**2*P_ra_min))**(1/4)\n",
    "        rw_anten =  res/res_max\n",
    "        required_anten =  rw_anten\n",
    "        done = False\n",
    "        # Calculate in Case the action meets the conditions\n",
    "        if k <= m:\n",
    "            if required_latency > standard_time:\n",
    "                com_reward = -standard_time\n",
    "            else:\n",
    "                com_reward = standard_time - required_latency\n",
    "            com_reward = com_reward * self.alpha1\n",
    "            cost_reward = required_fee * self.alpha2\n",
    "            anten_reward =  required_anten*self.alpha3\n",
    "            connect_reward = connect_rw*self.alpha4\n",
    "            total_reward = com_reward - cost_reward + anten_reward + connect_reward\n",
    "        else:\n",
    "            \"\"\"\n",
    "            an action doesn't meet the conditions\n",
    "            \"\"\"\n",
    "            com_reward = -1.0 * self.alpha1 * standard_time\n",
    "            cost_reward = 1.0 * self.alpha2 * required_fee\n",
    "            if m == 0:\n",
    "                cost_reward = (self.l / self.client_f) * self.max_c\n",
    "            anten_reward =  required_anten*self.alpha3\n",
    "            connect_reward = connect_rw*self.alpha4\n",
    "            total_reward = com_reward - cost_reward + anten_reward + connect_reward\n",
    "        reward = [total_reward, com_reward, cost_reward, anten_reward, connect_reward]\n",
    "        \n",
    "        \"\"\"\n",
    "        Move to the next State\n",
    "        \"\"\"\n",
    "        self.l = np.random.normal(loc=self.l, scale=self.max_l * 1e-6)\n",
    "        if self.l < 0:\n",
    "            self.l = self.max_l * 0.5\n",
    "\n",
    "        self. transmit(self.curr_n_helpers)\n",
    "        next_state = self.get_state()\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def sam_action(self):\n",
    "        \"\"\"\n",
    "        select one action randomly\n",
    "        action's format [k, a1, ..., aN]\n",
    "        \"\"\"\n",
    "        k = random.randint(1, self.n_helpers)\n",
    "        if k==1:\n",
    "          x=1\n",
    "        else:\n",
    "          x=k//1.5\n",
    "        n = random.randint(x, self.n_helpers)\n",
    "        # mylist = [0.7, 0.9]\n",
    "        # Power = []\n",
    "        # for i in range(len(mylist)):\n",
    "        #   if mylist[i]==0.7:\n",
    "        #     pw = 1\n",
    "        #   else:\n",
    "        #     pw = 2\n",
    "        #   Power.append(pw)\n",
    "\n",
    "        # mu = random.choice(Power)\n",
    "        mu=random.choice([1, 2])\n",
    "        a_vec = [0.0 for _ in range(self.n_helpers)]\n",
    "        sel_helper_idxs = np.random.permutation(self.n_helpers)[0:n]\n",
    "        for helper_idx in list(sel_helper_idxs):\n",
    "            a_vec[helper_idx] = 1.0\n",
    "        action = [k] + a_vec + [mu]\n",
    "        return action\n",
    "\n",
    "    def constrain(self, D, v_n, v_t, z_n, z_t):\n",
    "      duration = D/(v_n-v_t) - (z_n - z_t)/(v_n-v_t)\n",
    "      return duration\n",
    "\n",
    "    def action2index(self, action):\n",
    "        \"\"\"\n",
    "        Convert action from nulti-dimension format to index format\n",
    "        \"\"\"\n",
    "        if len(action) != len(self.act_dims):\n",
    "            raise Exception(\"Shape Error\")\n",
    "        \n",
    "        act_idx = action[0] - 1\n",
    "        for i in range(1, len(self.act_dims)-1):\n",
    "            act_idx = act_idx * self.act_dims[i] + action[i]\n",
    "        act_idx = act_idx * 2 + (action[-1] - 1)\n",
    "        return act_idx\n",
    "\n",
    "    def index2action(self, act_idx):\n",
    "        \"\"\"\n",
    "        Convert action from index format to multi-dimension format\n",
    "        \"\"\"\n",
    "        action = []\n",
    "        action_bw = act_idx % 2\n",
    "        act_idx = (act_idx - action_bw)/2\n",
    "        #action_bw = action_bw + 1\n",
    "        for i in range(len(self.act_dims)-1, 1, -1):\n",
    "            ai = act_idx % self.act_dims[i-1]\n",
    "            action.append(int(ai))\n",
    "            act_idx = (act_idx - ai) / self.act_dims[i-1]\n",
    "        \n",
    "        action.append(int(act_idx))\n",
    "        action = [action_bw+ 1] + action\n",
    "        action.reverse()\n",
    "        action[0] = action[0] + 1\n",
    "        return action\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = TaskOffloadEnv(n_helpers=5,rc=100,max_f=100,max_c=100,max_l=100,alpha1=1.0,alpha2=1.0,alpha3=1.0,alpha4=1.0, v_min=0,v_max=50,seed=1)\n",
    "    action = env.sam_action()\n",
    "    idx = env.action2index(action)\n",
    "    recovered = env.index2action(idx)\n",
    "    print(idx)\n",
    "    print(action, recovered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4sjAMk_TkrR"
   },
   "source": [
    "#Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jgRfkbF_TnZs"
   },
   "outputs": [],
   "source": [
    "n_helpers = 5\n",
    "rc = 100.0\n",
    "max_f = 2e9\n",
    "max_c = 1e2\n",
    "max_l = 3e5*8 # 8bits \n",
    "alpha1 = 2\n",
    "alpha2 = 30\n",
    "alpha3 = 5\n",
    "alpha4 = 5\n",
    "BW = 10e7\n",
    "seed = 1\n",
    "v_min = 0\n",
    "v_max = 10\n",
    "num_episodes = 70\n",
    "max_step_per_episode = 500\n",
    "buffer_size = 2000\n",
    "batch_size = 32\n",
    "max_eps = 1.0\n",
    "epsilon = max_eps\n",
    "min_eps = 0.1\n",
    "gpu_idx = -1\n",
    "log_dir = \"../log\"\n",
    "\n",
    "CHECKPOINT = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8f5EzimT488"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TwEPty6rT6mV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP 0 - Step 19  || Total 15.62758 - Comp 12.24902 - Cost 1.4913747825026173 - Res 2.8117066259517456 - Connect 1.525 - eps 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_1848\\2672084589.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_array = np.array(minibatch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "EP 0 - Step 39  || Total 24.24038 - Comp 21.43666 - Cost 2.3356424038837753 - Res 3.700414022461427 - Connect 1.75 - eps 0.9992002799440072\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "EP 0 - Step 59  || Total 9.25628 - Comp 6.12331 - Cost 1.3147828242504775 - Res 3.700414022461427 - Connect 1.325 - eps 0.9972037767260468\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "EP 0 - Step 79  || Total 12.29296 - Comp 9.18602 - Cost 1.699117925341732 - Res 2.8117066259517456 - Connect 1.55 - eps 0.9952112627234414\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "EP 0 - Step 99  || Total 15.37022 - Comp 12.24878 - Cost 1.7457533254419295 - Res 2.8117066259517456 - Connect 1.7 - eps 0.9932227299653352\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "EP 0 - Step 119  || Total 15.09053 - Comp 12.24906 - Cost 1.7507223467578623 - Res 2.8117066259517456 - Connect 1.425 - eps 0.9912381704967991\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "EP 0 - Step 139  || Total 3.11064 - Comp -0.00206 - Cost 1.1406173004058986 - Res 2.8117066259517456 - Connect 1.175 - eps 0.9892575763787981\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "EP 0 - Step 159  || Total 21.68633 - Comp 18.37492 - Cost 1.7446547249187692 - Res 3.700414022461427 - Connect 1.8 - eps 0.9872809396881612\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \t\t\u001b[39m#Experience Replay\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \t\t\u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dqn\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m batch_size:\n\u001b[1;32m---> 28\u001b[0m \t\t\tepsilon \u001b[39m=\u001b[39m dqn\u001b[39m.\u001b[39;49mexperience_replay(env, batch_size)\n\u001b[0;32m     29\u001b[0m     \u001b[39m#Update the weights after each episode (You can configure this for x steps as well\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \t\tepsilon \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(epsilon,min_eps)\n",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m, in \u001b[0;36mDoubleDeepQNetwork.experience_replay\u001b[1;34m(self, env, batch_size)\u001b[0m\n\u001b[0;32m     71\u001b[0m     st \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend( st, np_array[i,\u001b[39m0\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     72\u001b[0m     nst \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend( nst, np_array[i,\u001b[39m3\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# Because the store includes state, action, reward, nstate, and done\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m st_predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(st) \u001b[39m#Here is the speedup! I can predict on the ENTIRE batch\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m#print(f\"st_predict:{st_predict}\")\u001b[39;00m\n\u001b[0;32m     75\u001b[0m nst_predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(nst)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2002\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1995\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   1996\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1997\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1998\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTPUStrategy and AutoShardPolicy.FILE might lead to out-of-order \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1999\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresult. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2000\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> 2002\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2003\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2004\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2005\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2006\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2007\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2008\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2009\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2010\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2011\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2012\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   2014\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1401\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1400\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1401\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1151\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1148\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1150\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1152\u001b[0m     x,\n\u001b[0;32m   1153\u001b[0m     y,\n\u001b[0;32m   1154\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1155\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1156\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1157\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1158\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1159\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1160\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1161\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1162\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1163\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m   1165\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:326\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m     flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    324\u001b[0m   \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 326\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    328\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2092\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2059\u001b[0m   \u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2060\u001b[0m \n\u001b[0;32m   2061\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2090\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2091\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2092\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5327\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5325\u001b[0m \u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5326\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m-> 5327\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5328\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m   5329\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5330\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   5331\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5332\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2558\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2559\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2560\u001b[0m \n\u001b[0;32m   2561\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2566\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2567\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2568\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2569\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2570\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2531\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2532\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2533\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2534\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2535\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2536\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:312\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    310\u001b[0m num_in_full_batch \u001b[39m=\u001b[39m num_full_batches \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m    311\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mslice(indices, [\u001b[39m0\u001b[39m], [num_in_full_batch])\n\u001b[1;32m--> 312\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreshape(\n\u001b[0;32m    313\u001b[0m     first_k_indices, [num_full_batches, batch_size])\n\u001b[0;32m    315\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(first_k_indices)\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:202\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     67\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     69\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    203\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    204\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8545\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8543\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   8544\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 8545\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   8546\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, tensor\u001b[39m=\u001b[39;49mtensor, shape\u001b[39m=\u001b[39;49mshape, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   8547\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   8548\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    696\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3751\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3752\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3753\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3755\u001b[0m       node_def,\n\u001b[0;32m   3756\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3757\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3758\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3759\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3760\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3761\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3762\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2130\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2131\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1933\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1931\u001b[0m inputs \u001b[39m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[39m.\u001b[39mattr)\n\u001b[0;32m   1932\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1933\u001b[0m op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(graph\u001b[39m.\u001b[39;49m_c_graph,\n\u001b[0;32m   1934\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1935\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1936\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1937\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gamma = 0.99\n",
    "epsilon_decay = 0.9999\n",
    "env = TaskOffloadEnv(n_helpers,rc,max_f,max_c,max_l,alpha1,alpha2,alpha3, alpha4, v_min, v_max, seed)\n",
    "nS = env.env_dims\n",
    "print(nS)\n",
    "nA = env.num_actions\n",
    "print(nA)\n",
    "learning_rate = 1e-3\n",
    "discount_rate = gamma\n",
    "dqn = DoubleDeepQNetwork(nS, nA, learning_rate, discount_rate, epsilon, min_eps, epsilon_decay)\n",
    "log_total_reward_ddqn, log_comp_reward_ddqn, log_cost_reward_ddqn, log_anten_reward_ddqn, log_connect_reward_ddqn = [], [], [], [], []\n",
    "epsilon = max_eps\n",
    "frame_count = 0\n",
    "for episode in range(num_episodes):\n",
    "\tstate = env.reset()\n",
    "\tstate = np.reshape(state, [1, nS])\n",
    "\tfor step in range(max_step_per_episode):\n",
    "\t\tframe_count +=1\n",
    "\t\taction = dqn.action(env, state)\n",
    "\t\tnstate, reward, done = env.step(action)\n",
    "\t\tnstate = np.reshape(nstate, [1, nS])\n",
    "\n",
    "\t\tdqn.store(state, action, reward[0], nstate, done) # Resize to store in memory to pass to .predict\n",
    "\t\tstate = nstate\n",
    "\n",
    "\t\t#Experience Replay\n",
    "\t\tif len(dqn.memory) > batch_size:\n",
    "\t\t\tepsilon = dqn.experience_replay(env, batch_size)\n",
    "    #Update the weights after each episode (You can configure this for x steps as well\n",
    "\t\tepsilon = max(epsilon,min_eps)\n",
    "\t\n",
    "\t\t''' \n",
    "\t\t\tAverage & Print\n",
    "\t\t'''\n",
    "\t\tif ((step) % CHECKPOINT >= 0) and ((step) % CHECKPOINT <= CHECKPOINT - 1):\n",
    "\t\t\tif (step) % CHECKPOINT == 0:\n",
    "\t\t\t\tlist_total_ddqn, list_comp_ddqn, list_cost_ddqn, list_anten_ddqn, list_connect_ddqn = [], [], [], [], []\n",
    "\n",
    "\t\t\t\ttotal_reward_ddqn, comp_reward_ddqn, cost_reward_ddqn, anten_reward_ddqn, connect_reward_ddqn = 0, 0, 0, 0, 0\n",
    "\n",
    "\t\t\ttotal_reward_ddqn = reward[0]\n",
    "\t\t\tcomp_reward_ddqn = reward[1] \n",
    "\t\t\tcost_reward_ddqn = reward[2] \n",
    "\t\t\tanten_reward_ddqn = reward[3] \n",
    "\t\t\tconnect_reward_ddqn = reward[4]\n",
    "\t\t\tlist_total_ddqn.append(total_reward_ddqn)\n",
    "\t\t\tlist_comp_ddqn.append(comp_reward_ddqn)\n",
    "\t\t\tlist_cost_ddqn.append(cost_reward_ddqn)\n",
    "\t\t\tlist_anten_ddqn.append(anten_reward_ddqn)\n",
    "\t\t\tlist_connect_ddqn.append(connect_reward_ddqn)\n",
    "\n",
    "\t\t\tif (step) % CHECKPOINT == CHECKPOINT - 1:\t\t\n",
    "\t\t\t\tavg_total_ddqn = np.mean(list_total_ddqn)\n",
    "\t\t\t\tavg_comp_ddqn = np.mean(list_comp_ddqn)\n",
    "\t\t\t\tavg_anten_ddqn = np.mean(list_anten_ddqn)\n",
    "\t\t\t\tavg_cost_ddqn = np.mean(list_cost_ddqn)\n",
    "\t\t\t\tavg_connect_ddqn = np.mean(list_connect_ddqn)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tlog_total_reward_ddqn.append(avg_total_ddqn)\n",
    "\t\t\t\tlog_comp_reward_ddqn.append(avg_comp_ddqn)\n",
    "\t\t\t\tlog_cost_reward_ddqn.append(avg_cost_ddqn)\n",
    "\t\t\t\tlog_anten_reward_ddqn.append(avg_anten_ddqn)\n",
    "\t\t\t\tlog_connect_reward_ddqn.append(avg_connect_ddqn)\n",
    "\t\t\tif (step) % CHECKPOINT == CHECKPOINT - 1:\n",
    "\t\t\t\tprint(\"EP {} - Step {}  || Total {:.5f} - Comp {:.5f} - Cost {} - Res {} - Connect {} - eps {}\".\\\n",
    "\t\t\t\t\tformat(episode, step, avg_total_ddqn, avg_comp_ddqn, avg_cost_ddqn, anten_reward_ddqn, avg_connect_ddqn, epsilon))\n",
    "\t\tif step == max_step_per_episode-1:\n",
    "\t\t\tprint(f\"Episode {episode} end\")\n",
    "\t\t\tdone = True\n",
    "\t\tif reward[0] >= 4000:  # Condition to consider the task solved\n",
    "\t\t\tprint(\"Break at step {}!\".format(step))\n",
    "\t\t\tdone = True\n",
    "\t\t\tbreak\n",
    "\tdqn.update_target_from_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHqqfvLJT_0u"
   },
   "source": [
    "#Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAaUA9SPUBeZ"
   },
   "outputs": [],
   "source": [
    "aver_ddqn = []\n",
    "step = (len(log_total_reward_ddqn)+1)/num_episodes\n",
    "for i in range(0, len(log_total_reward_ddqn), int(step)):\n",
    "  ddqn_eps_i = log_total_reward_ddqn[i:i+int(step)-1]\n",
    "  aver_ddqn.append(np.mean(ddqn_eps_i))\n",
    "  i += 1\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(aver_ddqn, \"^-\", label=' DDQN: rewards', linewidth=1.75)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\" Total Reward\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUn7aigLUDiR"
   },
   "source": [
    "#Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azkrroLJUGLC"
   },
   "outputs": [],
   "source": [
    "step = len(log_total_reward_ddqn)/num_episodes\n",
    "import os\n",
    "from datetime import datetime\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "save_path = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "model_path = \"_DDQN_10L.csv\"\n",
    "path = save_path + model_path\n",
    "print(path)\n",
    "episode = num_episodes \n",
    "num = int(step)*episode\n",
    "with open(f'{path}','w') as f: \n",
    "    write = csv.writer(f) \n",
    "    for i in range(num):\n",
    "         write.writerow([log_total_reward_ddqn[i], log_comp_reward_ddqn[i], log_cost_reward_ddqn[i], log_anten_reward_ddqn[i], log_connect_reward_ddqn[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667388900040,
     "user": {
      "displayName": "Duong Minh",
      "userId": "05553484543028094036"
     },
     "user_tz": -540
    },
    "id": "OBwydQmdH1T8",
    "outputId": "4d51ddef-b2f0-4891-e345-c0782f05cc75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04164179 -0.01426203 -0.05955468  0.03592912  0.22629712]\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 5)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL_IxyHcPeIk"
   },
   "outputs": [],
   "source": [
    "mu_list  = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "var_list = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "State_1 = np.random.gumbel(mu_list[0], var_list[0], 5)\n",
    "State_2 = np.random.gumbel(mu_list[1], var_list[1], 5)\n",
    "State_3 = np.random.normal(mu_list[2], var_list[2], 5)\n",
    "State_4 = np.random.gumbel(mu_list[3], var_list[3], 5)\n",
    "State_5 = np.random.gumbel(mu_list[4], var_list[4], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667391000783,
     "user": {
      "displayName": "Duong Minh",
      "userId": "05553484543028094036"
     },
     "user_tz": -540
    },
    "id": "sZRM3i4dPs7b",
    "outputId": "98659914-6b98-4315-a6a6-4088cc5c74a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70400706 0.15484451 0.32537986 0.87441763 0.59696479]\n",
      "[1.92378685 0.15137752 0.33060696 1.11487445 0.7597304 ]\n",
      "[ 0.771421    0.1067      0.09077265  1.07483478 -0.61847047]\n",
      "[ 1.8149219   0.07554243 -0.07782807  0.91912907  0.45081901]\n",
      "[0.77183882 0.04623204 0.43918218 0.76848853 0.75061073]\n"
     ]
    }
   ],
   "source": [
    "print(State_1)\n",
    "print(State_2)\n",
    "print(State_3)\n",
    "print(State_4)\n",
    "print(State_5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
